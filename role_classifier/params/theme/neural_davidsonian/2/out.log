2021-03-09 19:25:53,659 - INFO - allennlp.common.params - random_seed = 13370
2021-03-09 19:25:53,659 - INFO - allennlp.common.params - numpy_seed = 1337
2021-03-09 19:25:53,660 - INFO - allennlp.common.params - pytorch_seed = 133
2021-03-09 19:25:53,661 - INFO - allennlp.common.checks - Pytorch version: 1.7.1
2021-03-09 19:25:53,662 - INFO - allennlp.common.params - type = default
2021-03-09 19:25:53,662 - INFO - allennlp.common.params - dataset_reader.type = uds_reader
2021-03-09 19:25:53,663 - INFO - allennlp.common.params - dataset_reader.token_indexers = None
2021-03-09 19:25:53,663 - INFO - allennlp.common.params - dataset_reader.lazy = False
2021-03-09 19:25:53,663 - INFO - allennlp.common.params - train_data_path = data/train_theme.json
2021-03-09 19:25:53,664 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f7c5fd1dc70>
2021-03-09 19:25:53,664 - INFO - allennlp.common.params - datasets_for_vocab_creation = None
2021-03-09 19:25:53,664 - INFO - allennlp.common.params - validation_dataset_reader = None
2021-03-09 19:25:53,665 - INFO - allennlp.common.params - validation_data_path = data/dev_theme.json
2021-03-09 19:25:53,665 - INFO - allennlp.common.params - validation_data_loader = None
2021-03-09 19:25:53,665 - INFO - allennlp.common.params - test_data_path = None
2021-03-09 19:25:53,665 - INFO - allennlp.common.params - evaluate_on_test = False
2021-03-09 19:25:53,666 - INFO - allennlp.common.params - batch_weight_key = 
2021-03-09 19:25:53,666 - INFO - allennlp.training.util - Reading training data from data/train_theme.json
2021-03-09 19:25:53,670 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2021-03-09 19:25:54,092 - INFO - allennlp.training.util - Reading validation data from data/dev_theme.json
2021-03-09 19:25:54,092 - INFO - tqdm - reading instances: 0it [00:00, ?it/s]
2021-03-09 19:25:54,269 - INFO - allennlp.common.params - type = from_instances
2021-03-09 19:25:54,270 - INFO - allennlp.common.params - min_count = None
2021-03-09 19:25:54,270 - INFO - allennlp.common.params - max_vocab_size = None
2021-03-09 19:25:54,270 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')
2021-03-09 19:25:54,270 - INFO - allennlp.common.params - pretrained_files = None
2021-03-09 19:25:54,270 - INFO - allennlp.common.params - only_include_pretrained_words = False
2021-03-09 19:25:54,271 - INFO - allennlp.common.params - tokens_to_add = None
2021-03-09 19:25:54,271 - INFO - allennlp.common.params - min_pretrained_embeddings = None
2021-03-09 19:25:54,271 - INFO - allennlp.common.params - padding_token = @@PADDING@@
2021-03-09 19:25:54,271 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@
2021-03-09 19:25:54,271 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.
2021-03-09 19:25:54,272 - INFO - tqdm - building vocab: 0it [00:00, ?it/s]
2021-03-09 19:25:54,362 - INFO - allennlp.common.params - model.type = neural_davidsonian
2021-03-09 19:25:54,363 - INFO - allennlp.common.params - model.embedder.type = basic
2021-03-09 19:25:54,363 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.type = embedding
2021-03-09 19:25:54,364 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.embedding_dim = 50
2021-03-09 19:25:54,364 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.num_embeddings = None
2021-03-09 19:25:54,364 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.projection_dim = None
2021-03-09 19:25:54,365 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.weight = None
2021-03-09 19:25:54,365 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.padding_index = None
2021-03-09 19:25:54,365 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.trainable = False
2021-03-09 19:25:54,365 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.max_norm = None
2021-03-09 19:25:54,365 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.norm_type = 2.0
2021-03-09 19:25:54,366 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.scale_grad_by_freq = False
2021-03-09 19:25:54,366 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.sparse = False
2021-03-09 19:25:54,366 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.vocab_namespace = tokens
2021-03-09 19:25:54,366 - INFO - allennlp.common.params - model.embedder.token_embedders.tokens.pretrained_file = (http://nlp.stanford.edu/data/glove.6B.zip)#glove.6B.50d.txt
2021-03-09 19:25:54,367 - INFO - allennlp.modules.token_embedders.embedding - Reading pretrained embeddings from file
2021-03-09 19:25:55,115 - INFO - allennlp.common.file_utils - cache of http://nlp.stanford.edu/data/glove.6B.zip is up-to-date
2021-03-09 19:25:58,025 - INFO - allennlp.common.file_utils - cache of http://nlp.stanford.edu/data/glove.6B.zip is up-to-date
2021-03-09 19:25:58,027 - INFO - tqdm - 0it [00:00, ?it/s]
2021-03-09 19:25:59,793 - INFO - allennlp.modules.token_embedders.embedding - Initializing pre-trained embedding layer
2021-03-09 19:25:59,865 - INFO - allennlp.modules.token_embedders.embedding - Pretrained embeddings were found for 6218 out of 8856 tokens
2021-03-09 19:25:59,868 - INFO - allennlp.common.params - model.encoder.type = lstm
2021-03-09 19:25:59,869 - INFO - allennlp.common.params - model.encoder.input_size = 50
2021-03-09 19:25:59,869 - INFO - allennlp.common.params - model.encoder.hidden_size = 25
2021-03-09 19:25:59,869 - INFO - allennlp.common.params - model.encoder.num_layers = 1
2021-03-09 19:25:59,869 - INFO - allennlp.common.params - model.encoder.bias = True
2021-03-09 19:25:59,870 - INFO - allennlp.common.params - model.encoder.dropout = 0.0
2021-03-09 19:25:59,870 - INFO - allennlp.common.params - model.encoder.bidirectional = True
2021-03-09 19:25:59,870 - INFO - allennlp.common.params - model.encoder.stateful = False
2021-03-09 19:25:59,984 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2021-03-09 19:25:59,985 - INFO - allennlp.common.params - data_loader.batch_size = 10
2021-03-09 19:25:59,985 - INFO - allennlp.common.params - data_loader.shuffle = True
2021-03-09 19:25:59,985 - INFO - allennlp.common.params - data_loader.sampler = None
2021-03-09 19:25:59,985 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2021-03-09 19:25:59,986 - INFO - allennlp.common.params - data_loader.num_workers = 0
2021-03-09 19:25:59,986 - INFO - allennlp.common.params - data_loader.pin_memory = False
2021-03-09 19:25:59,986 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-03-09 19:25:59,986 - INFO - allennlp.common.params - data_loader.timeout = 0
2021-03-09 19:25:59,987 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2021-03-09 19:25:59,987 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2021-03-09 19:25:59,987 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-03-09 19:25:59,987 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader
2021-03-09 19:25:59,988 - INFO - allennlp.common.params - data_loader.batch_size = 10
2021-03-09 19:25:59,988 - INFO - allennlp.common.params - data_loader.shuffle = True
2021-03-09 19:25:59,988 - INFO - allennlp.common.params - data_loader.sampler = None
2021-03-09 19:25:59,988 - INFO - allennlp.common.params - data_loader.batch_sampler = None
2021-03-09 19:25:59,988 - INFO - allennlp.common.params - data_loader.num_workers = 0
2021-03-09 19:25:59,989 - INFO - allennlp.common.params - data_loader.pin_memory = False
2021-03-09 19:25:59,989 - INFO - allennlp.common.params - data_loader.drop_last = False
2021-03-09 19:25:59,989 - INFO - allennlp.common.params - data_loader.timeout = 0
2021-03-09 19:25:59,989 - INFO - allennlp.common.params - data_loader.worker_init_fn = None
2021-03-09 19:25:59,989 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None
2021-03-09 19:25:59,989 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None
2021-03-09 19:25:59,990 - INFO - allennlp.common.params - trainer.type = gradient_descent
2021-03-09 19:25:59,990 - INFO - allennlp.common.params - trainer.patience = 3
2021-03-09 19:25:59,990 - INFO - allennlp.common.params - trainer.validation_metric = -loss
2021-03-09 19:25:59,990 - INFO - allennlp.common.params - trainer.num_epochs = 10
2021-03-09 19:25:59,991 - INFO - allennlp.common.params - trainer.cuda_device = -1
2021-03-09 19:25:59,991 - INFO - allennlp.common.params - trainer.grad_norm = None
2021-03-09 19:25:59,991 - INFO - allennlp.common.params - trainer.grad_clipping = 5
2021-03-09 19:25:59,991 - INFO - allennlp.common.params - trainer.distributed = False
2021-03-09 19:25:59,991 - INFO - allennlp.common.params - trainer.world_size = 1
2021-03-09 19:25:59,992 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1
2021-03-09 19:25:59,992 - INFO - allennlp.common.params - trainer.use_amp = False
2021-03-09 19:25:59,992 - INFO - allennlp.common.params - trainer.no_grad = None
2021-03-09 19:25:59,992 - INFO - allennlp.common.params - trainer.learning_rate_scheduler = None
2021-03-09 19:25:59,992 - INFO - allennlp.common.params - trainer.momentum_scheduler = None
2021-03-09 19:25:59,993 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f7c5fd7ceb0>
2021-03-09 19:25:59,994 - INFO - allennlp.common.params - trainer.moving_average = None
2021-03-09 19:25:59,994 - INFO - allennlp.common.params - trainer.checkpointer = <allennlp.common.lazy.Lazy object at 0x7f7c5fd7cfa0>
2021-03-09 19:25:59,994 - INFO - allennlp.common.params - trainer.batch_callbacks = None
2021-03-09 19:25:59,995 - INFO - allennlp.common.params - trainer.epoch_callbacks = None
2021-03-09 19:25:59,995 - INFO - allennlp.common.params - trainer.end_callbacks = None
2021-03-09 19:25:59,995 - INFO - allennlp.common.params - trainer.trainer_callbacks = None
2021-03-09 19:25:59,996 - INFO - allennlp.common.params - trainer.optimizer.type = adam
2021-03-09 19:25:59,996 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None
2021-03-09 19:25:59,996 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.001
2021-03-09 19:25:59,997 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)
2021-03-09 19:25:59,997 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08
2021-03-09 19:25:59,997 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0
2021-03-09 19:25:59,997 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False
2021-03-09 19:25:59,997 - INFO - allennlp.training.optimizers - Number of trainable parameters: 15602
2021-03-09 19:25:59,998 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):
2021-03-09 19:25:59,998 - INFO - allennlp.common.util - _embedder.token_embedder_tokens.weight
2021-03-09 19:25:59,999 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):
2021-03-09 19:25:59,999 - INFO - allennlp.common.util - _encoder._module.weight_ih_l0
2021-03-09 19:25:59,999 - INFO - allennlp.common.util - _encoder._module.weight_hh_l0
2021-03-09 19:25:59,999 - INFO - allennlp.common.util - _encoder._module.bias_ih_l0
2021-03-09 19:26:00,000 - INFO - allennlp.common.util - _encoder._module.bias_hh_l0
2021-03-09 19:26:00,000 - INFO - allennlp.common.util - _encoder._module.weight_ih_l0_reverse
2021-03-09 19:26:00,000 - INFO - allennlp.common.util - _encoder._module.weight_hh_l0_reverse
2021-03-09 19:26:00,000 - INFO - allennlp.common.util - _encoder._module.bias_ih_l0_reverse
2021-03-09 19:26:00,001 - INFO - allennlp.common.util - _encoder._module.bias_hh_l0_reverse
2021-03-09 19:26:00,001 - INFO - allennlp.common.util - _classifier.weight
2021-03-09 19:26:00,001 - INFO - allennlp.common.util - _classifier.bias
2021-03-09 19:26:00,002 - INFO - allennlp.common.params - type = default
2021-03-09 19:26:00,003 - INFO - allennlp.common.params - keep_serialized_model_every_num_seconds = None
2021-03-09 19:26:00,004 - INFO - allennlp.common.params - num_serialized_models_to_keep = 2
2021-03-09 19:26:00,004 - INFO - allennlp.common.params - model_save_interval = None
2021-03-09 19:26:00,004 - INFO - allennlp.common.params - summary_interval = 100
2021-03-09 19:26:00,004 - INFO - allennlp.common.params - histogram_interval = None
2021-03-09 19:26:00,004 - INFO - allennlp.common.params - batch_size_interval = None
2021-03-09 19:26:00,005 - INFO - allennlp.common.params - should_log_parameter_statistics = True
2021-03-09 19:26:00,005 - INFO - allennlp.common.params - should_log_learning_rate = False
2021-03-09 19:26:00,005 - INFO - allennlp.common.params - get_batch_num_total = None
2021-03-09 19:26:00,026 - INFO - allennlp.training.trainer - Beginning training.
2021-03-09 19:26:00,026 - INFO - allennlp.training.trainer - Epoch 0/9
2021-03-09 19:26:00,026 - INFO - allennlp.training.trainer - Worker 0 memory usage: 268M
2021-03-09 19:26:00,027 - INFO - allennlp.training.trainer - Training
2021-03-09 19:26:00,027 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:26:10,084 - INFO - tqdm - precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 0.6740, loss: 0.6664 ||:  48%|####8     | 273/567 [00:10<00:09, 30.62it/s]
2021-03-09 19:26:20,231 - INFO - tqdm - precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 0.6735, loss: 0.6554 ||:  98%|#########8| 558/567 [00:20<00:00, 29.05it/s]
2021-03-09 19:26:20,491 - INFO - tqdm - precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 0.7054, loss: 0.6558 ||: 100%|#########9| 566/567 [00:20<00:00, 29.72it/s]
2021-03-09 19:26:20,521 - INFO - tqdm - precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 0.6742, loss: 0.6558 ||: 100%|##########| 567/567 [00:20<00:00, 27.67it/s]
2021-03-09 19:26:20,526 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:26:20,527 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:26:21,032 - INFO - tqdm - precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 0.4844, loss: 0.6431 ||: 100%|##########| 76/76 [00:00<00:00, 150.75it/s]
2021-03-09 19:26:21,032 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-03-09 19:26:21,033 - INFO - allennlp.training.tensorboard_writer - f1                 |     0.000  |     0.000
2021-03-09 19:26:21,034 - INFO - allennlp.training.tensorboard_writer - loss               |     0.656  |     0.643
2021-03-09 19:26:21,034 - INFO - allennlp.training.tensorboard_writer - precision          |     0.000  |     0.000
2021-03-09 19:26:21,035 - INFO - allennlp.training.tensorboard_writer - recall             |     0.000  |     0.000
2021-03-09 19:26:21,035 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   268.152  |       N/A
2021-03-09 19:26:21,040 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'role_classifier/params/theme/neural_davidsonian/2//best.th'.
2021-03-09 19:26:21,052 - INFO - allennlp.training.trainer - Epoch duration: 0:00:21.026045
2021-03-09 19:26:21,053 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:09
2021-03-09 19:26:21,053 - INFO - allennlp.training.trainer - Epoch 1/9
2021-03-09 19:26:21,053 - INFO - allennlp.training.trainer - Worker 0 memory usage: 276M
2021-03-09 19:26:21,054 - INFO - allennlp.training.trainer - Training
2021-03-09 19:26:21,054 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:26:31,165 - INFO - tqdm - precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 0.6752, loss: 0.6451 ||:  50%|####9     | 283/567 [00:10<00:10, 26.49it/s]
2021-03-09 19:26:41,248 - INFO - tqdm - precision: 0.0000, recall: 0.0000, f1: 0.0000, batch_loss: 0.7157, loss: 0.6410 ||:  91%|######### | 514/567 [00:20<00:02, 24.95it/s]
2021-03-09 19:26:43,454 - INFO - tqdm - precision: 0.5000, recall: 0.0005, f1: 0.0010, batch_loss: 0.5722, loss: 0.6409 ||: 100%|#########9| 566/567 [00:22<00:00, 19.95it/s]
2021-03-09 19:26:43,501 - INFO - tqdm - precision: 0.6667, recall: 0.0010, f1: 0.0021, batch_loss: 0.5929, loss: 0.6409 ||: 100%|##########| 567/567 [00:22<00:00, 25.26it/s]
2021-03-09 19:26:43,510 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:26:43,511 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:26:44,210 - INFO - tqdm - precision: 0.5000, recall: 0.0037, f1: 0.0074, batch_loss: 0.4393, loss: 0.6425 ||: 100%|##########| 76/76 [00:00<00:00, 108.74it/s]
2021-03-09 19:26:44,211 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-03-09 19:26:44,211 - INFO - allennlp.training.tensorboard_writer - f1                 |     0.002  |     0.007
2021-03-09 19:26:44,212 - INFO - allennlp.training.tensorboard_writer - loss               |     0.641  |     0.642
2021-03-09 19:26:44,213 - INFO - allennlp.training.tensorboard_writer - precision          |     0.667  |     0.500
2021-03-09 19:26:44,214 - INFO - allennlp.training.tensorboard_writer - recall             |     0.001  |     0.004
2021-03-09 19:26:44,214 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   276.117  |       N/A
2021-03-09 19:26:44,219 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'role_classifier/params/theme/neural_davidsonian/2//best.th'.
2021-03-09 19:26:44,236 - INFO - allennlp.training.trainer - Epoch duration: 0:00:23.182455
2021-03-09 19:26:44,236 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:56
2021-03-09 19:26:44,236 - INFO - allennlp.training.trainer - Epoch 2/9
2021-03-09 19:26:44,237 - INFO - allennlp.training.trainer - Worker 0 memory usage: 277M
2021-03-09 19:26:44,238 - INFO - allennlp.training.trainer - Training
2021-03-09 19:26:44,238 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:26:54,330 - INFO - tqdm - precision: 0.5000, recall: 0.0016, f1: 0.0033, batch_loss: 0.6462, loss: 0.6422 ||:  31%|###       | 175/567 [00:10<00:19, 20.52it/s]
2021-03-09 19:27:04,389 - INFO - tqdm - precision: 0.5000, recall: 0.0014, f1: 0.0028, batch_loss: 0.7379, loss: 0.6398 ||:  72%|#######1  | 408/567 [00:20<00:06, 24.63it/s]
2021-03-09 19:27:11,475 - INFO - tqdm - precision: 0.4545, recall: 0.0026, f1: 0.0052, batch_loss: 0.7384, loss: 0.6393 ||: 100%|#########9| 565/567 [00:27<00:00, 25.45it/s]
2021-03-09 19:27:11,567 - INFO - tqdm - precision: 0.4545, recall: 0.0026, f1: 0.0051, batch_loss: 0.6280, loss: 0.6396 ||: 100%|##########| 567/567 [00:27<00:00, 20.75it/s]
2021-03-09 19:27:11,573 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:27:11,574 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:27:12,183 - INFO - tqdm - precision: 1.0000, recall: 0.0037, f1: 0.0075, batch_loss: 0.8573, loss: 0.6478 ||: 100%|##########| 76/76 [00:00<00:00, 124.87it/s]
2021-03-09 19:27:12,184 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-03-09 19:27:12,184 - INFO - allennlp.training.tensorboard_writer - f1                 |     0.005  |     0.007
2021-03-09 19:27:12,185 - INFO - allennlp.training.tensorboard_writer - loss               |     0.640  |     0.648
2021-03-09 19:27:12,186 - INFO - allennlp.training.tensorboard_writer - precision          |     0.455  |     1.000
2021-03-09 19:27:12,187 - INFO - allennlp.training.tensorboard_writer - recall             |     0.003  |     0.004
2021-03-09 19:27:12,188 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   277.133  |       N/A
2021-03-09 19:27:12,193 - INFO - allennlp.training.trainer - Epoch duration: 0:00:27.956292
2021-03-09 19:27:12,193 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:48
2021-03-09 19:27:12,193 - INFO - allennlp.training.trainer - Epoch 3/9
2021-03-09 19:27:12,194 - INFO - allennlp.training.trainer - Worker 0 memory usage: 277M
2021-03-09 19:27:12,194 - INFO - allennlp.training.trainer - Training
2021-03-09 19:27:12,195 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:27:22,248 - INFO - tqdm - precision: 1.0000, recall: 0.0026, f1: 0.0052, batch_loss: 0.4834, loss: 0.6305 ||:  41%|####1     | 234/567 [00:10<00:14, 23.27it/s]
2021-03-09 19:27:32,436 - INFO - tqdm - precision: 0.5000, recall: 0.0019, f1: 0.0038, batch_loss: 0.6353, loss: 0.6385 ||:  82%|########2 | 466/567 [00:20<00:05, 17.28it/s]
2021-03-09 19:27:36,508 - INFO - tqdm - precision: 0.5000, recall: 0.0057, f1: 0.0113, batch_loss: 0.6942, loss: 0.6390 ||: 100%|#########9| 566/567 [00:24<00:00, 23.96it/s]
2021-03-09 19:27:36,547 - INFO - tqdm - precision: 0.5000, recall: 0.0057, f1: 0.0112, batch_loss: 0.8048, loss: 0.6393 ||: 100%|##########| 567/567 [00:24<00:00, 23.28it/s]
2021-03-09 19:27:36,553 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:27:36,553 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:27:37,147 - INFO - tqdm - precision: 1.0000, recall: 0.0150, f1: 0.0295, batch_loss: 0.4270, loss: 0.6478 ||: 100%|##########| 76/76 [00:00<00:00, 128.05it/s]
2021-03-09 19:27:37,148 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-03-09 19:27:37,149 - INFO - allennlp.training.tensorboard_writer - f1                 |     0.011  |     0.030
2021-03-09 19:27:37,149 - INFO - allennlp.training.tensorboard_writer - loss               |     0.639  |     0.648
2021-03-09 19:27:37,151 - INFO - allennlp.training.tensorboard_writer - precision          |     0.500  |     1.000
2021-03-09 19:27:37,151 - INFO - allennlp.training.tensorboard_writer - recall             |     0.006  |     0.015
2021-03-09 19:27:37,151 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   277.273  |       N/A
2021-03-09 19:27:37,157 - INFO - allennlp.training.trainer - Epoch duration: 0:00:24.963604
2021-03-09 19:27:37,157 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:25
2021-03-09 19:27:37,158 - INFO - allennlp.training.trainer - Epoch 4/9
2021-03-09 19:27:37,158 - INFO - allennlp.training.trainer - Worker 0 memory usage: 278M
2021-03-09 19:27:37,158 - INFO - allennlp.training.trainer - Training
2021-03-09 19:27:37,159 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:27:47,293 - INFO - tqdm - precision: 0.5294, recall: 0.0107, f1: 0.0210, batch_loss: 0.7050, loss: 0.6443 ||:  43%|####2     | 241/567 [00:10<00:14, 22.49it/s]
2021-03-09 19:27:57,301 - INFO - tqdm - precision: 0.5581, recall: 0.0149, f1: 0.0290, batch_loss: 0.6687, loss: 0.6381 ||:  83%|########3 | 471/567 [00:20<00:04, 22.65it/s]
2021-03-09 19:28:01,381 - INFO - tqdm - precision: 0.5769, recall: 0.0155, f1: 0.0303, batch_loss: 0.7441, loss: 0.6377 ||: 100%|#########9| 565/567 [00:24<00:00, 23.76it/s]
2021-03-09 19:28:01,462 - INFO - tqdm - precision: 0.5769, recall: 0.0155, f1: 0.0302, batch_loss: 0.5883, loss: 0.6378 ||: 100%|##########| 567/567 [00:24<00:00, 23.33it/s]
2021-03-09 19:28:01,468 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:28:01,469 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:28:02,066 - INFO - tqdm - precision: 0.6667, recall: 0.0524, f1: 0.0972, batch_loss: 0.4673, loss: 0.6413 ||: 100%|##########| 76/76 [00:00<00:00, 127.36it/s]
2021-03-09 19:28:02,067 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-03-09 19:28:02,067 - INFO - allennlp.training.tensorboard_writer - f1                 |     0.030  |     0.097
2021-03-09 19:28:02,068 - INFO - allennlp.training.tensorboard_writer - loss               |     0.638  |     0.641
2021-03-09 19:28:02,069 - INFO - allennlp.training.tensorboard_writer - precision          |     0.577  |     0.667
2021-03-09 19:28:02,070 - INFO - allennlp.training.tensorboard_writer - recall             |     0.015  |     0.052
2021-03-09 19:28:02,070 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   277.586  |       N/A
2021-03-09 19:28:02,074 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'role_classifier/params/theme/neural_davidsonian/2//best.th'.
2021-03-09 19:28:02,090 - INFO - allennlp.training.trainer - Epoch duration: 0:00:24.932438
2021-03-09 19:28:02,091 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:02
2021-03-09 19:28:02,091 - INFO - allennlp.training.trainer - Epoch 5/9
2021-03-09 19:28:02,092 - INFO - allennlp.training.trainer - Worker 0 memory usage: 278M
2021-03-09 19:28:02,092 - INFO - allennlp.training.trainer - Training
2021-03-09 19:28:02,093 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:28:12,102 - INFO - tqdm - precision: 0.6000, recall: 0.0293, f1: 0.0558, batch_loss: 0.7933, loss: 0.6332 ||:  43%|####2     | 241/567 [00:10<00:15, 21.09it/s]
2021-03-09 19:28:22,172 - INFO - tqdm - precision: 0.5495, recall: 0.0299, f1: 0.0568, batch_loss: 0.6783, loss: 0.6386 ||:  85%|########5 | 483/567 [00:20<00:03, 26.55it/s]
2021-03-09 19:28:25,826 - INFO - tqdm - precision: 0.5728, recall: 0.0305, f1: 0.0579, batch_loss: 0.5585, loss: 0.6363 ||: 100%|#########9| 566/567 [00:23<00:00, 21.27it/s]
2021-03-09 19:28:25,896 - INFO - tqdm - precision: 0.5728, recall: 0.0304, f1: 0.0578, batch_loss: 0.6737, loss: 0.6363 ||: 100%|##########| 567/567 [00:23<00:00, 23.82it/s]
2021-03-09 19:28:25,903 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:28:25,904 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:28:26,497 - INFO - tqdm - precision: 0.8182, recall: 0.0337, f1: 0.0647, batch_loss: 0.4235, loss: 0.6461 ||: 100%|##########| 76/76 [00:00<00:00, 128.15it/s]
2021-03-09 19:28:26,498 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-03-09 19:28:26,498 - INFO - allennlp.training.tensorboard_writer - f1                 |     0.058  |     0.065
2021-03-09 19:28:26,499 - INFO - allennlp.training.tensorboard_writer - loss               |     0.636  |     0.646
2021-03-09 19:28:26,500 - INFO - allennlp.training.tensorboard_writer - precision          |     0.573  |     0.818
2021-03-09 19:28:26,501 - INFO - allennlp.training.tensorboard_writer - recall             |     0.030  |     0.034
2021-03-09 19:28:26,501 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   277.586  |       N/A
2021-03-09 19:28:26,507 - INFO - allennlp.training.trainer - Epoch duration: 0:00:24.415387
2021-03-09 19:28:26,507 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:37
2021-03-09 19:28:26,507 - INFO - allennlp.training.trainer - Epoch 6/9
2021-03-09 19:28:26,508 - INFO - allennlp.training.trainer - Worker 0 memory usage: 278M
2021-03-09 19:28:26,508 - INFO - allennlp.training.trainer - Training
2021-03-09 19:28:26,509 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:28:36,555 - INFO - tqdm - precision: 0.6000, recall: 0.0249, f1: 0.0478, batch_loss: 0.5076, loss: 0.6385 ||:  43%|####2     | 243/567 [00:10<00:13, 23.32it/s]
2021-03-09 19:28:46,656 - INFO - tqdm - precision: 0.6232, recall: 0.0264, f1: 0.0506, batch_loss: 0.3882, loss: 0.6364 ||:  84%|########3 | 476/567 [00:20<00:04, 21.19it/s]
2021-03-09 19:28:50,525 - INFO - tqdm - precision: 0.6164, recall: 0.0232, f1: 0.0448, batch_loss: 0.6235, loss: 0.6368 ||: 100%|##########| 567/567 [00:24<00:00, 21.83it/s]
2021-03-09 19:28:50,525 - INFO - tqdm - precision: 0.6164, recall: 0.0232, f1: 0.0448, batch_loss: 0.6235, loss: 0.6368 ||: 100%|##########| 567/567 [00:24<00:00, 23.61it/s]
2021-03-09 19:28:50,533 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:28:50,533 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:28:51,138 - INFO - tqdm - precision: 0.7500, recall: 0.0225, f1: 0.0436, batch_loss: 1.5766, loss: 0.6589 ||: 100%|##########| 76/76 [00:00<00:00, 125.81it/s]
2021-03-09 19:28:51,139 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation
2021-03-09 19:28:51,139 - INFO - allennlp.training.tensorboard_writer - f1                 |     0.045  |     0.044
2021-03-09 19:28:51,140 - INFO - allennlp.training.tensorboard_writer - loss               |     0.637  |     0.659
2021-03-09 19:28:51,141 - INFO - allennlp.training.tensorboard_writer - precision          |     0.616  |     0.750
2021-03-09 19:28:51,142 - INFO - allennlp.training.tensorboard_writer - recall             |     0.023  |     0.022
2021-03-09 19:28:51,142 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |   277.621  |       N/A
2021-03-09 19:28:51,283 - INFO - allennlp.training.trainer - Epoch duration: 0:00:24.775306
2021-03-09 19:28:51,284 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:13
2021-03-09 19:28:51,284 - INFO - allennlp.training.trainer - Epoch 7/9
2021-03-09 19:28:51,284 - INFO - allennlp.training.trainer - Worker 0 memory usage: 278M
2021-03-09 19:28:51,285 - INFO - allennlp.training.trainer - Training
2021-03-09 19:28:51,285 - INFO - tqdm - 0%|          | 0/567 [00:00<?, ?it/s]
2021-03-09 19:29:01,311 - INFO - tqdm - precision: 0.6190, recall: 0.0159, f1: 0.0311, batch_loss: 0.5820, loss: 0.6320 ||:  43%|####2     | 243/567 [00:10<00:12, 26.45it/s]
2021-03-09 19:29:11,315 - INFO - tqdm - precision: 0.5926, recall: 0.0295, f1: 0.0562, batch_loss: 0.5789, loss: 0.6338 ||:  84%|########3 | 475/567 [00:20<00:04, 21.74it/s]
2021-03-09 19:29:15,512 - INFO - tqdm - precision: 0.5600, recall: 0.0289, f1: 0.0550, batch_loss: 0.6941, loss: 0.6347 ||: 100%|##########| 567/567 [00:24<00:00, 24.96it/s]
2021-03-09 19:29:15,512 - INFO - tqdm - precision: 0.5600, recall: 0.0289, f1: 0.0550, batch_loss: 0.6941, loss: 0.6347 ||: 100%|##########| 567/567 [00:24<00:00, 23.40it/s]
2021-03-09 19:29:15,518 - INFO - allennlp.training.trainer - Validating
2021-03-09 19:29:15,519 - INFO - tqdm - 0%|          | 0/76 [00:00<?, ?it/s]
2021-03-09 19:29:16,126 - INFO - tqdm - precision: 0.5000, recall: 0.0262, f1: 0.0498, batch_loss: 0.4283, loss: 0.6504 ||: 100%|##########| 76/76 [00:00<00:00, 125.30it/s]
2021-03-09 19:29:16,127 - INFO - allennlp.training.trainer - Ran out of patience.  Stopping training.
2021-03-09 19:29:16,127 - INFO - allennlp.training.checkpointer - loading best weights
2021-03-09 19:29:16,145 - INFO - allennlp.common.util - Metrics: {
  "best_epoch": 4,
  "peak_worker_0_memory_MB": 277.63671875,
  "training_duration": "0:02:51.116750",
  "training_start_epoch": 0,
  "training_epochs": 6,
  "epoch": 6,
  "training_precision": 0.6164383292198181,
  "training_recall": 0.023219814524054527,
  "training_f1": 0.04475385323166847,
  "training_loss": 0.636769827448712,
  "training_worker_0_memory_MB": 277.62109375,
  "validation_precision": 0.75,
  "validation_recall": 0.02247191034257412,
  "validation_f1": 0.04363636299967766,
  "validation_loss": 0.6588594207638189,
  "best_validation_precision": 0.6666666865348816,
  "best_validation_recall": 0.05243445560336113,
  "best_validation_f1": 0.0972222238779068,
  "best_validation_loss": 0.6413406808125345
}
2021-03-09 19:29:16,148 - INFO - allennlp.models.archival - archiving weights and vocabulary to role_classifier/params/theme/neural_davidsonian/2/model.tar.gz
